{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBd1YpgrbSt8"
      },
      "outputs": [],
      "source": [
        "def fetch_nasa_power_data(latitude, longitude, start_date, end_date):\n",
        "    \"\"\"\n",
        "    this part of the project\n",
        "    collects data from the API\n",
        "    \"\"\"\n",
        "    base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
        "    params = {\n",
        "        \"parameters\": \"ALLSKY_SFC_SW_DWN,WS10M,T2M\",\n",
        "        \"community\": \"RE\",\n",
        "        \"longitude\": longitude,\n",
        "        \"latitude\": latitude,\n",
        "        \"start\": start_date,\n",
        "        \"end\": end_date,\n",
        "        \"format\": \"JSON\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "\n",
        "    return response.json()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_dataframe(data, lat, lon):\n",
        "    #makes the dataframe from the API ingestion\n",
        "    parameters = data.get('properties', {}).get('parameter', {})\n",
        "    allsky = parameters.get('ALLSKY_SFC_SW_DWN', {})\n",
        "    ws10m = parameters.get('WS10M', {})\n",
        "    t2m = parameters.get('T2M', {})\n",
        "\n",
        "    records = []\n",
        "    for date_str, allsky_val in allsky.items():\n",
        "        ws10m_val = ws10m.get(date_str, -999.0)\n",
        "        t2m_val = t2m.get(date_str, -999.0)\n",
        "\n",
        "\n",
        "        date_obj = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
        "\n",
        "        records.append({\n",
        "            \"latitude\": lat,\n",
        "            \"longitude\": lon,\n",
        "            \"date\": date_obj,\n",
        "            \"allsky_sfc_sw_dwn\": allsky_val,\n",
        "            \"ws10m\": ws10m_val,\n",
        "            \"t2m\": t2m_val\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "SIk0QPAEbZMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "lat_min, lat_max, lat_step = 5, 55, 5\n",
        "lon_min, lon_max, lon_step = -135, -90, 5\n",
        "\n",
        "start = \"20160901\"\n",
        "end = \"20161231\"\n",
        "output_filename = \"solar_radiation_data.csv\"\n",
        "\n",
        "\n",
        "conn = sqlite3.connect('solar_data.db')\n",
        "\n",
        "\n",
        "for lat in range(5, 60, 5):\n",
        "    for lon in range(-135, -85, 5):\n",
        "\n",
        "\n",
        "        data = fetch_nasa_power_data(lat, lon, start, end)\n",
        "        print(f\"Successfully fetched data for this lat/lon\", lat, lon)\n",
        "\n",
        "        df = convert_to_dataframe(data, lat, lon)\n",
        "\n",
        "        df.to_sql('solar_radiation', conn, if_exists=\"append\", index=False)\n",
        "        print(f\"Persisted the rows for latitude:{lat}, longitude:{lon} to DB.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "\n",
        "cur = conn.cursor()\n",
        "cur.execute(\n",
        "    \"SELECT name FROM sqlite_master WHERE type='table' AND name=?;\",\n",
        "    (TABLE_NAME,)\n",
        ")\n",
        "table_exists = cur.fetchone() is not None\n",
        "\n",
        "\n",
        "big_df = pd.read_sql_query(f\"SELECT * FROM solar_radiation;\", conn)\n",
        "big_df.to_csv(\"solar_radiation_data.csv\", index=False)\n",
        "print(f\"\\nSuccessfully saved all data from DB to {output_filename}.\")\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "GWIeKnZTba3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_and_clean_solar_data(csv_path: str) -> pd.DataFrame:\n",
        "\n",
        "\n",
        "\n",
        "  df = pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "  df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "  df = df.dropna(subset=[\"date\"])\n",
        "\n",
        "\n",
        "  numeric_cols = [\"allsky_sfc_sw_dwn\", \"ws10m\", \"t2m\"]\n",
        "\n",
        "\n",
        "  for col in numeric_cols:\n",
        "      if col in df.columns:\n",
        "          df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "\n",
        "  df[\"year\"]        = df[\"date\"].dt.year\n",
        "  df[\"month\"]       = df[\"date\"].dt.month\n",
        "  df[\"day\"]         = df[\"date\"].dt.day\n",
        "  df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
        "\n",
        "\n",
        "  doy = df[\"day_of_year\"].astype(float)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "dsFy448xbjMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df_nasa = pd.read_csv(\"/content/solar_radiation_data.csv\")\n",
        "df_sensor = pd.read_csv(\"/content/SolarPrediction.csv\")\n",
        "\n",
        "\n",
        "df_nasa[\"date\"] = pd.to_datetime(df_nasa[\"date\"]).dt.date\n",
        "\n",
        "\n",
        "# this was done to merge the datetime\n",
        "df_sensor[\"datetime\"] = pd.to_datetime(\n",
        "    df_sensor[\"Data\"].str.strip(),\n",
        "    format=\"%m/%d/%Y %I:%M:%S %p\"\n",
        ")\n",
        "\n",
        "\n",
        "df_sensor[\"date\"] = df_sensor[\"datetime\"].dt.date\n",
        "\n",
        "\n",
        "target_lat = df_nasa[\"latitude\"].iloc[0]\n",
        "target_lon = df_nasa[\"longitude\"].iloc[0]\n",
        "\n",
        "df_nasa_site = df_nasa[\n",
        "    (df_nasa[\"latitude\"] == target_lat) &\n",
        "    (df_nasa[\"longitude\"] == target_lon)\n",
        "].copy()\n",
        "\n",
        "target_lat = df_nasa[\"latitude\"].iloc[0]\n",
        "target_lon = df_nasa[\"longitude\"].iloc[0]\n",
        "\n",
        "df_nasa_site = df_nasa[\n",
        "    (df_nasa[\"latitude\"] == target_lat) &\n",
        "    (df_nasa[\"longitude\"] == target_lon)\n",
        "].copy()\n",
        "\n",
        "#this merges the dataframe\n",
        "merged_df = pd.merge(df_sensor, df_nasa_site, on=\"date\",how=\"left\")\n",
        "\n",
        "\n",
        "merged_df.to_csv(\"merged_df.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(merged_df.head())\n",
        "\n",
        "print(len(merged_df))\n"
      ],
      "metadata": {
        "id": "vq8VzGYKbmYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "X_train_reg = X_train_scaled\n",
        "X_test_reg = X_test_scaled\n",
        "y_train = Y_train.iloc[:, 0]\n",
        "y_test = Y_test.iloc[:,0]\n",
        "\n",
        "#code for decision tree  regression\n",
        "\n",
        "decision_tree_model = DecisionTreeRegressor(max_depth = 7, random_state = 84)\n",
        "decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "decision_regression_prediction_training = decision_tree_model.predict(X_train)\n",
        "decision_regression_prediction_testing = decision_tree_model.predict(X_test)\n",
        "\n",
        "error_decision_train = mean_squared_error(y_train, decision_regression_prediction_training)\n",
        "error_decision_test = mean_squared_error(y_test, decision_regression_prediction_testing)\n",
        "r2_decision_train = r2_score(y_train, decision_regression_prediction_training)\n",
        "r2_decision_test = r2_score(y_test, decision_regression_prediction_testing)\n",
        "print(\"Below are the outputs for decision tree regressor\")\n",
        "print(\"Train error: \", np.sqrt(error_decision_train))\n",
        "print(\"Test error: \", np.sqrt(error_decision_test))\n",
        "print(\"Train R2: \", r2_decision_train)\n",
        "print(\"Test R2: \", r2_decision_train)\n",
        "\n",
        "#Code for forest regressor\n",
        "#code for decision tree  regression\n",
        "\n",
        "forest_tree_model = RandomForestRegressor(n_estimators = 1, random_state = 42)\n",
        "forest_tree_model.fit(X_train, y_train)\n",
        "\n",
        "forest_regression_prediction_training = forest_tree_model.predict(X_train)\n",
        "forest_regression_prediction_testing = forest_tree_model.predict(X_test)\n",
        "\n",
        "error_forest_train = mean_squared_error(y_train, forest_regression_prediction_training)\n",
        "error_forest_test = mean_squared_error(y_test, forest_regression_prediction_testing)\n",
        "r2_forest_train = r2_score(y_train, forest_regression_prediction_training)\n",
        "r2_forest_test = r2_score(y_train, forest_regression_prediction_training)\n",
        "print(\"Below are the outputs for decision tree regressor\")\n",
        "print(\"Train error: \", np.sqrt(error_forest_train))\n",
        "print(\"Test error: \", np.sqrt(error_forest_test))\n",
        "print(\"Train R2: \", r2_forest_train)\n",
        "print(\"Test R2: \", r2_forest_test)\n",
        "\n",
        "#Code for gxboost regressor\n",
        "\n",
        "xgb_tree_model = XGBRegressor(n_estimators = 1, learning_rate = .01)\n",
        "xgb_tree_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_regression_prediction_training = xgb_tree_model.predict(X_train)\n",
        "xgb_regression_prediction_testing = xgb_tree_model.predict(X_test)\n",
        "\n",
        "error_xgb_train = mean_squared_error(y_train, xgb_regression_prediction_training)\n",
        "error_xgb_test = mean_squared_error(y_test, xgb_regression_prediction_testing)\n",
        "r2_xgb_train = r2_score(y_train, xgb_regression_prediction_training)\n",
        "r2_xgb_test = r2_score(y_train, xgb_regression_prediction_training)\n",
        "print(\"Below are the outputs for xgb tree regressor\")\n",
        "print(\"Train error: \", np.sqrt(error_forest_train))\n",
        "print(\"Test error: \", np.sqrt(error_forest_test))\n",
        "print(\"Train R2: \", r2_forest_train)\n",
        "print(\"Test R2: \", r2_forest_test)\n",
        "\n",
        "#graphing forest, we deemed it best\n",
        "plt.figure(figsize = (20,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.scatter(y_train, forest_regression_prediction_training, alpha = .5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw =2)\n",
        "plt.xlabel(\"Actual values\")\n",
        "plt.ylabel(\"Predicted values\")\n",
        "plt.title(\"Actual vs Predicted Values for Forest Regression\")\n",
        "\n",
        "residuals = y_test - forest_regression_prediction_testing\n",
        "plt.subplot(1,3,2)\n",
        "plt.scatter(forest_regression_prediction_testing, residuals, alpha = .5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw =2)\n",
        "plt.xlabel(\"Predicted values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot for Random Forest\")\n",
        "\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "coef_values = forest_tree_model.feature_importances_\n",
        "#just to make it more viewable in colab UI, we restricted to 8 features\n",
        "features = [f\"feature_{i}\" for i in range(X_train_reg.shape[1])]\n",
        "coefficients = forest_tree_model.feature_importances_\n",
        "coef_series = pd.Series(coefficients, index = features)\n",
        "coef_series_shortened = coef_series.head(8)\n",
        "coef_series_shortened.plot(kind = 'barh')\n",
        "plt.tight_layout()\n",
        "plt.title(\"Feature Importance of Forest Model\")\n",
        "plt.xlabel(\"Coefficient Value\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2GHO25LYbrHe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}